{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Important: The EAST text requires that your input image dimensions be multiples of 32,\n",
    "so if you choose to adjust your --width and --height values, make sure they are multiples of 32!\n",
    "'''\n",
    "\n",
    "# load the input image and grab the image dimensions\n",
    "image = cv2.imread(r\"E:\\AI Practice Project\\cv\\basic project\\Dont-Forget-To-Pray-Tonight-8bit.png\")\n",
    "orig = image.copy()\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# set the new width and height and then \n",
    "(newW, newH) = (320, 320)\n",
    "\n",
    "# determine the ratio in change for both the width and height\n",
    "rW = W / float(newW)\n",
    "rH = H / float(newH)\n",
    "\n",
    "# resize the image and grab the new image dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "\n",
    "# In order to perform text detection using OpenCV and the EAST deep learning model, we need to extract the output feature maps of two layers:\n",
    "\n",
    "''' The first layer = \n",
    "is our output sigmoid activation which gives us the probability of a region containing text or not.\n",
    "\n",
    "The second layer = \n",
    "is the output feature map that represents the “geometry” of the image, \n",
    "we will be able to use this geometry to derive the bounding box coordinates of the text in the input image '''\n",
    "layerNames = [\n",
    "\t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "\t\"feature_fusion/concat_3\"]\n",
    "\n",
    "\n",
    "# load the pre-trained EAST text detector\n",
    "net = cv2.dnn.readNet(r\"E:\\AI Practice Project\\cv\\basic project\\frozen_east_text_detection.pb\")\n",
    "\n",
    "# construct a blob from the image and then perform a forward pass of the model to obtain the two output layer sets\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H), (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "start = time.time()\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)\n",
    "end = time.time()\n",
    "\n",
    "# show timing information on text prediction\n",
    "print(f\"[INFO] text detection took {end - start} seconds\")\n",
    "\n",
    "\n",
    "# grab the number of rows and columns from the scores volume, then initialize our set of bounding box rectangles and corresponding confidence scores\n",
    "(numRows, numCols) = scores.shape[2:4]\n",
    "\n",
    "# loop over the number of rows\n",
    "rects = []\n",
    "confidences = []\n",
    "\n",
    "for y in range(0, numRows):\n",
    "\t# extract the scores (probabilities), followed by the geometrical data used to derive potential bounding box coordinates that surround text\n",
    "\tscoresData = scores[0, 0, y]\n",
    "\txData0 = geometry[0, 0, y]\n",
    "\txData1 = geometry[0, 1, y]\n",
    "\txData2 = geometry[0, 2, y]\n",
    "\txData3 = geometry[0, 3, y]\n",
    "\tanglesData = geometry[0, 4, y]\n",
    "\n",
    "\n",
    "\t# loop over the number of columns\n",
    "\tfor x in range(0, numCols):\n",
    "\n",
    "\t\t# if our score does not have sufficient probability, ignore it\n",
    "\t\tif scoresData[x] > 0.5:\t\t # 0.5 ==> min_confidence\n",
    "\t\t\n",
    "\n",
    "\t\t\t# compute the offset factor as our resulting feature maps will be 4x smaller than the input image\n",
    "\t\t\t(offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "\t\t\t# extract the rotation angle for the prediction and then compute the sin and cosine\n",
    "\t\t\tangle = anglesData[x]\n",
    "\t\t\tcos = np.cos(angle)\n",
    "\t\t\tsin = np.sin(angle)\n",
    "\n",
    "\t\t\t# use the geometry volume to derive the width and height of the bounding box\n",
    "\t\t\th = xData0[x] + xData2[x]\n",
    "\t\t\tw = xData1[x] + xData3[x]\n",
    "\n",
    "\t\t\t# compute both the starting and ending (x, y)-coordinates for the text prediction bounding box\n",
    "\t\t\tendX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "\t\t\tendY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "\t\t\tstartX = int(endX - w)\n",
    "\t\t\tstartY = int(endY - h)\n",
    "\n",
    "\t\t\t# add the bounding box coordinates and probability score to our respective lists\n",
    "\t\t\trects.append((startX, startY, endX, endY))\n",
    "\t\t\tconfidences.append(scoresData[x])\n",
    "\n",
    "\n",
    "\n",
    "# apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\n",
    "# loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "\n",
    "\t# scale the bounding box coordinates based on the respective ratios\n",
    "\tstartX = int(startX * rW)\n",
    "\tstartY = int(startY * rH)\n",
    "\tendX = int(endX * rW)\n",
    "\tendY = int(endY * rH)\n",
    "\n",
    "\t# draw the bounding box on the image\n",
    "\tcv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Text Detection\", orig)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image = frame\n",
    "    orig = image.copy()\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # set the new width and height and then \n",
    "    (newW, newH) = (320, 320)\n",
    "\n",
    "    # determine the ratio in change for both the width and height\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "\n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "\n",
    "    # In order to perform text detection using OpenCV and the EAST deep learning model, we need to extract the output feature maps of two layers:\n",
    "\n",
    "    ''' The first layer = \n",
    "    is our output sigmoid activation which gives us the probability of a region containing text or not.\n",
    "\n",
    "    The second layer = \n",
    "    is the output feature map that represents the “geometry” of the image, \n",
    "    we will be able to use this geometry to derive the bounding box coordinates of the text in the input image '''\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"]\n",
    "\n",
    "\n",
    "    # load the pre-trained EAST text detector\n",
    "    net = cv2.dnn.readNet(r\"E:\\AI Practice Project\\cv\\basic project\\frozen_east_text_detection.pb\")\n",
    "\n",
    "    # construct a blob from the image and then perform a forward pass of the model to obtain the two output layer sets\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H), (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "   \n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "    # grab the number of rows and columns from the scores volume, then initialize our set of bounding box rectangles and corresponding confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "\n",
    "    # loop over the number of rows\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the geometrical data used to derive potential bounding box coordinates that surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "\n",
    "            # if our score does not have sufficient probability, ignore it\n",
    "            if scoresData[x] < 0.5:\t\t # 0.5 ==> min_confidence\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature maps will be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            # extract the rotation angle for the prediction and then compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height of the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            # compute both the starting and ending (x, y)-coordinates for the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            # add the bounding box coordinates and probability score to our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "\n",
    "        # scale the bounding box coordinates based on the respective ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "\n",
    "        # draw the bounding box on the image\n",
    "        cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "    # show the output image\n",
    "    cv2.imshow(\"Text Detection\", orig)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xff\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
