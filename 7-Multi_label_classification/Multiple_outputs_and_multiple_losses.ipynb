{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### import dataset from kaggle"
      ],
      "metadata": {
        "id": "49u8egvbt329"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install opendatasets"
      ],
      "metadata": {
        "id": "t-KQ2oqGr_yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets\n",
        "\n",
        "opendatasets.download(\"https://www.kaggle.com/datasets/kaiska/apparel-dataset/download?datasetVersionNumber=2\")\n"
      ],
      "metadata": {
        "id": "CIhXM3Cvs2cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FashionNet architecture"
      ],
      "metadata": {
        "id": "DDNDSUqLuQaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Lambda, Dense, Flatten, Input\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class FashionNet:\n",
        "\n",
        "  @staticmethod\n",
        "  def build_category_branch(inputs, numCategories, finalAct=\"softmax\", chanDim=-1):\n",
        "\n",
        "    # utilize a lambda layer to convert the 3 channel input to a grayscale representation\n",
        "    x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
        "\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # (CONV => RELU) * 2 => POOL\n",
        "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # (CONV => RELU) * 2 => POOL\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # define a branch of output layers for the number of different clothing categories (i.e., shirts, jeans, dresses, etc.)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # The last activation layer is fully connected and has the same number of neurons/outputs as our numCategories\n",
        "    x = Dense(numCategories)(x)\n",
        "    x = Activation(finalAct, name=\"category_output\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def build_color_branch(inputs, numColors, finalAct=\"softmax\", chanDim=-1):\n",
        "\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=chanDim)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # define a branch of output layers for the number of different colors (i.e., red, black, blue, etc.)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # the final activation layer for the color branch\n",
        "    x = Dense(numColors)(x)\n",
        "    x = Activation(finalAct, name=\"color_output\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def build(width, height, numCategories, numColors, finalAct=\"softmax\"):\n",
        "    inputShape = (height, width, 3)\n",
        "    chanDim = -1\n",
        "\n",
        "    # construct both the \"category\" and \"color\" sub-networks\n",
        "    inputs = Input(shape=inputShape)    # Input(shape=None,batch_size=None,name=None,dtype=None,sparse=None,tensor=None,ragged=None,type_spec=None,**kwargs)\n",
        "\n",
        "    categoryBranch = FashionNet.build_category_branch(inputs,\n",
        "      numCategories, finalAct=finalAct, chanDim=chanDim)\n",
        "\n",
        "    colorBranch = FashionNet.build_color_branch(inputs,\n",
        "      numColors, finalAct=finalAct, chanDim=chanDim)\n",
        "\n",
        "\n",
        "    # create the model using our input (the batch of images) and\n",
        "    # two separate outputs -- one for the clothing category branch and another for the color branch, respectively\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=[categoryBranch, colorBranch], name=\"fashionnet\")\n",
        "\n",
        "    # return the constructed network architecture\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "BWJcW6Ojw-N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocess"
      ],
      "metadata": {
        "id": "TdCWaQeAMY8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# initialize the number of epochs to train for, initial learning rate, batch size, and image dimensions\n",
        "EPOCHS = 50\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "IMAGE_DIMS = (96, 96, 3)\n",
        "\n",
        "\n",
        "'''\n",
        "image path another method:\n",
        "l = []\n",
        "for root, dirs, files in os.walk('/content/apparel-dataset'):\n",
        "  for file in files:\n",
        "    l.append(os.path.join(root, file))\n",
        "\n",
        "print(l)\n",
        "'''\n",
        "\n",
        "imagePaths = sorted(list(paths.list_images(\"/content/apparel-dataset\")))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "\n",
        "# initialize the data, clothing category labels (i.e., shirts, jeans,\n",
        "# dresses, etc.) along with the color labels (i.e., red, blue, etc.)\n",
        "data = []\n",
        "categoryLabels = []\n",
        "colorLabels = []\n",
        "\n",
        "# loop over the input images\n",
        "for imagePath in imagePaths:\n",
        "  # load the image, pre-process it, and store it in the data list\n",
        "  image = cv2.imread(imagePath)\n",
        "  image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image = img_to_array(image)\n",
        "  data.append(image)\n",
        "\n",
        "  # extract the clothing color and category from the path and update the respective lists\n",
        "  (color, cat) = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
        "  categoryLabels.append(cat)\n",
        "  colorLabels.append(color)\n",
        "\n",
        "\n",
        "# scale the raw pixel intensities to the range [0, 1] and convert to a NumPy array\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "\n",
        "# convert the label lists to NumPy arrays prior to binarization\n",
        "categoryLabels = np.array(categoryLabels)\n",
        "colorLabels = np.array(colorLabels)\n",
        "\n",
        "# binarize both sets of labels\n",
        "categoryLB = LabelBinarizer()\n",
        "colorLB = LabelBinarizer()\n",
        "categoryLabels = categoryLB.fit_transform(categoryLabels)\n",
        "colorLabels = colorLB.fit_transform(colorLabels)\n",
        "\n",
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainCategoryY, testCategoryY, trainColorY, testColorY) = train_test_split(data, categoryLabels, colorLabels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q0k1s0pJMalZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compile and train"
      ],
      "metadata": {
        "id": "r_QIcmoK3mti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize our FashionNet multi-output network\n",
        "model = FashionNet().build(96, 96, numCategories= len(categoryLB.classes_), numColors=len(colorLB.classes_), finalAct=\"softmax\")\n",
        "\n",
        "# define two dictionaries: one that specifies the loss method for\n",
        "# each output of the network along with a second dictionary that\n",
        "# specifies the weight per loss\n",
        "losses = {\n",
        "    \"category_output\": \"categorical_crossentropy\",\n",
        "    \"color_output\": \"categorical_crossentropy\"}\n",
        "\n",
        "\n",
        "# loss_weights allows you to specify the contribution of each loss function to the total training loss.\n",
        "# This is useful for multi-task learning models where you want to balance multiple objectives.\n",
        "lossWeights = {\"category_output\": 1.0, \"color_output\": 1.0}\n",
        "\n",
        "# initialize the optimizer and compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=losses, loss_weights=lossWeights, metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "H = model.fit(x = trainX,\n",
        "              y = {\"category_output\": trainCategoryY, \"color_output\": trainColorY},\n",
        "              validation_data=(testX, {\"category_output\": testCategoryY, \"color_output\": testColorY}),\n",
        "              epochs=EPOCHS,\n",
        "              verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYFJa8v40mLs",
        "outputId": "f90dfab1-64b8-4881-dc62-0fc0d05d7fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "405/405 [==============================] - ETA: 0s - loss: 1.8155 - category_output_loss: 0.9815 - color_output_loss: 0.8340 - category_output_accuracy: 0.6955 - color_output_accuracy: 0.7299"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summery()"
      ],
      "metadata": {
        "id": "PfaesJwNFf63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### save model and labels"
      ],
      "metadata": {
        "id": "-B55F8ocGPvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Multiple_outputs_and_multiple_losses.hdf5\")\n",
        "\n",
        "# save the category binarizer to disk\n",
        "with open(\"categoryLabels\", 'wb') as f:\n",
        "  pickle.dump(categoryLB,f)\n",
        "\n",
        "# save the color binarizer to disk\n",
        "with open(\"categoryLabels\", 'wb') as b:\n",
        "  pickle.dump(colorLB,b)\n",
        "\n"
      ],
      "metadata": {
        "id": "nZyT3wOoGUku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plot"
      ],
      "metadata": {
        "id": "nGVLLlOLIrjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the total loss, category loss, and color loss\n",
        "lossNames = [\"loss\", \"category_output_loss\", \"color_output_loss\"]\n",
        "plt.style.use(\"ggplot\")\n",
        "(fig, ax) = plt.subplots(3, 1, figsize=(13, 13))\n",
        "\n",
        "# loop over the loss names\n",
        "for (i, l) in enumerate(lossNames):\n",
        "  # plot the loss for both the training and validation data\n",
        "  title = \"Loss for {}\".format(l) if l != \"loss\" else \"Total loss\"\n",
        "  ax[i].set_title(title)\n",
        "  ax[i].set_xlabel(\"Epoch #\")\n",
        "  ax[i].set_ylabel(\"Loss\")\n",
        "  ax[i].plot(np.arange(0, EPOCHS), H.history[l], label=l)\n",
        "  ax[i].plot(np.arange(0, EPOCHS), H.history[\"val_\" + l],\n",
        "    label=\"val_\" + l)\n",
        "  ax[i].legend()\n",
        "\n",
        "# save the losses figure\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"losses.png\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "x9XFcULAHBNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new figure for the accuracies\n",
        "accuracyNames = [\"category_output_accuracy\", \"color_output_accuracy\"]\n",
        "plt.style.use(\"ggplot\")\n",
        "(fig, ax) = plt.subplots(2, 1, figsize=(8, 8))\n",
        "# loop over the accuracy names\n",
        "for (i, l) in enumerate(accuracyNames):\n",
        "  # plot the loss for both the training and validation data\n",
        "  ax[i].set_title(\"Accuracy for {}\".format(l))\n",
        "  ax[i].set_xlabel(\"Epoch #\")\n",
        "  ax[i].set_ylabel(\"Accuracy\")\n",
        "  ax[i].plot(np.arange(0, EPOCHS), H.history[l], label=l)\n",
        "  ax[i].plot(np.arange(0, EPOCHS), H.history[\"val_\" + l],\n",
        "    label=\"val_\" + l)\n",
        "  ax[i].legend()\n",
        "# save the accuracies figure\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"accuracies.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "BoEF6nRoOMM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load model and test image"
      ],
      "metadata": {
        "id": "51FxpeuATLXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import pickle\n",
        "import cv2\n",
        "\n",
        "\n",
        "# load the image\n",
        "image = cv2.imread(\"/kaggle/input/img-test/pants-thm-02c.jpg\")\n",
        "output = imutils.resize(image, width=400)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# pre-process the image for classification\n",
        "image = cv2.resize(image, (96, 96))\n",
        "image = image.astype(\"float\") / 255.0\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# load the trained convolutional neural network from disk, followed\n",
        "# by the category and color label binarizers, respectively\n",
        "\n",
        "model = load_model(\"/kaggle/working/Multiple_outputs_and_multiple_losses.hdf5\")\n",
        "\n",
        "with open(\"/kaggle/working/categoryLabels\", \"rb\") as f:\n",
        "    categoryLB = pickle.load(f)\n",
        "\n",
        "with open(\"/kaggle/working/colorLabels\", \"rb\") as s:\n",
        "    colorLB = pickle.load(s)\n",
        "\n",
        "\n",
        "\n",
        "# classify the input image using Keras' multi-output functionality\n",
        "(categoryProba, colorProba) = model.predict(image)\n",
        "\n",
        "# find indexes of both the category and color outputs with the\n",
        "# largest probabilities, then determine the corresponding class labels\n",
        "categoryIdx = categoryProba[0].argmax()\n",
        "colorIdx = colorProba[0].argmax()\n",
        "categoryLabel = categoryLB.classes_[categoryIdx]\n",
        "colorLabel = colorLB.classes_[colorIdx]"
      ],
      "metadata": {
        "id": "BUAlQlytRLzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(categoryLabel)\n",
        "print(colorLabel)"
      ],
      "metadata": {
        "id": "4ZP8PKNvZg_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}