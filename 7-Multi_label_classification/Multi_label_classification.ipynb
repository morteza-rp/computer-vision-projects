{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "!git clone https://github.com/MichaelCai311/keras-multi-label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8o5QDK6GwTv",
        "outputId": "54005f74-56fd-45e3-811f-17ae2c21b3ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'keras-multi-label'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 217 (delta 6), reused 201 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (217/217), 31.33 MiB | 35.14 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization,Conv2D ,MaxPooling2D ,Activation ,Flatten ,Dropout,Dense\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "DIQ10rkN7LZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallerVGGNet:\n",
        "\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, num_classes, finalAct = 'softmax'):\n",
        "\n",
        "    ''' The depth= specifies the number of channels in an input image,\n",
        "        and num_classes= is the number (integer) of categories/classes (not the class labels themselves).\n",
        "        We’ll use these parameters in our training script to instantiate the model with a 96 x 96 x 3 input volume. '''\n",
        "\n",
        "    # initialize the model along with the input shape to be\n",
        "    # \"channels last\" and the channels dimension itself\n",
        "    model = Sequential()\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "\n",
        "    # Since we’re using the TensorFlow backend,\n",
        "    # we arrange the input shape with “channels last” data ordering,\n",
        "    # but if you want to use “channels first” (Theano, etc.)\n",
        "\n",
        "    # if we are using \"channels first\", update the input shape\n",
        "    # and channels dimension\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "      inputShape = (depth, height, width)\n",
        "      chanDim = 1\n",
        "\n",
        "    # CONV => RELU => POOL\n",
        "    model.add(Conv2D(32, (3,3), padding = 'same', input_shape = inputShape))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    # (CONV => RELU) * 2 => POOL\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "    # (CONV => RELU) * 2 => POOL\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "    # first (and only) set of FC => RELU layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    # softmax classifier\n",
        "    model.add(Dense(num_classes))\n",
        "    ''' finalAct dictates whether we’ll use \"softmax\" activation for single-label classification\n",
        "        or \"sigmoid\" activation in the case of today’s multi-label classification. '''\n",
        "    model.add(Activation(finalAct))\n",
        "\n",
        "    # return the constructed network architecture\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "lBrgzxyKDLGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# batch size, and image dimensions\n",
        "EPOCHS = 30\n",
        "INIT_LR = 1e-3\n",
        "BS = 16\n",
        "IMAGE_DIMS = (96, 96, 3)\n",
        "\n",
        "# disable eager execution\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################     loading and preprocessing our training data:      ###################################\n",
        "\n",
        "\n",
        "imagePaths = sorted(list(paths.list_images('/content/dataset')))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "\n",
        "# initialize the data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# loop over the input images\n",
        "for imagePath in imagePaths:\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "    image = img_to_array(image)\n",
        "    data.append(image)\n",
        "\n",
        "    # extract set of class labels from the image path and update the\n",
        "    # labels list\n",
        "    label = imagePath.split(os.path.sep)[-2].split(\"_\")       # os.path.sep ===>  '/'\n",
        "    labels.append(label)\n",
        "\n",
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "# print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(\n",
        "#\tlen(imagePaths), data.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "# binarize the labels using scikit-learn's special multi-label\n",
        "# binarizer implementation\n",
        "mlb = MultiLabelBinarizer()\n",
        "labels = mlb.fit_transform(labels)\n",
        "\n",
        "# loop over each of the possible class labels and show them\n",
        "#for (i, label) in enumerate(labels):\n",
        "#    print(f\"{i + 1}. {label}\")\n",
        "\n",
        "\n",
        "# partition the data into training and testing splits using 80% of the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n"
      ],
      "metadata": {
        "id": "q6RFj6dpJOa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model using a sigmoid activation as the final layer\n",
        "# in the network so we can perform multi-label classification\n",
        "\n",
        "model = SmallerVGGNet()\n",
        "model = model.build(\n",
        "    width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
        "    depth=IMAGE_DIMS[2], num_classes=len(labels[1]),\n",
        "    finalAct=\"sigmoid\")\n",
        "\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\tx=aug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnXdJ07fn5Pw",
        "outputId": "9cd872da-bae7-4cdc-ff6e-6a2bace22c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/30\n",
            "9/9 [==============================] - 9s 669ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.5786 - accuracy: 0.7350 - val_loss: 0.6322 - val_accuracy: 0.6991\n",
            "Epoch 2/30\n",
            "9/9 [==============================] - 12s 1s/step - batch: 4.0000 - size: 16.0000 - loss: 0.3661 - accuracy: 0.8715 - val_loss: 0.6702 - val_accuracy: 0.5741\n",
            "Epoch 3/30\n",
            "9/9 [==============================] - 12s 1s/step - batch: 4.0000 - size: 16.0000 - loss: 0.2784 - accuracy: 0.9005 - val_loss: 0.7833 - val_accuracy: 0.6250\n",
            "Epoch 4/30\n",
            "9/9 [==============================] - 7s 795ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.2402 - accuracy: 0.9074 - val_loss: 0.7447 - val_accuracy: 0.5880\n",
            "Epoch 5/30\n",
            "9/9 [==============================] - 6s 626ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1825 - accuracy: 0.9317 - val_loss: 0.8391 - val_accuracy: 0.7037\n",
            "Epoch 6/30\n",
            "9/9 [==============================] - 6s 681ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1949 - accuracy: 0.9329 - val_loss: 0.9367 - val_accuracy: 0.6343\n",
            "Epoch 7/30\n",
            "9/9 [==============================] - 6s 651ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.2183 - accuracy: 0.9306 - val_loss: 1.1724 - val_accuracy: 0.6111\n",
            "Epoch 8/30\n",
            "9/9 [==============================] - 5s 605ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1732 - accuracy: 0.9398 - val_loss: 1.4629 - val_accuracy: 0.6019\n",
            "Epoch 9/30\n",
            "9/9 [==============================] - 7s 750ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1280 - accuracy: 0.9560 - val_loss: 1.1269 - val_accuracy: 0.6574\n",
            "Epoch 10/30\n",
            "9/9 [==============================] - 5s 619ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1413 - accuracy: 0.9479 - val_loss: 1.2769 - val_accuracy: 0.6111\n",
            "Epoch 11/30\n",
            "9/9 [==============================] - 7s 773ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1189 - accuracy: 0.9664 - val_loss: 1.3958 - val_accuracy: 0.6343\n",
            "Epoch 12/30\n",
            "9/9 [==============================] - 6s 657ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1635 - accuracy: 0.9502 - val_loss: 1.2053 - val_accuracy: 0.5972\n",
            "Epoch 13/30\n",
            "9/9 [==============================] - 7s 782ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0988 - accuracy: 0.9653 - val_loss: 1.2895 - val_accuracy: 0.5972\n",
            "Epoch 14/30\n",
            "9/9 [==============================] - 9s 1s/step - batch: 4.0000 - size: 16.0000 - loss: 0.1100 - accuracy: 0.9630 - val_loss: 1.2927 - val_accuracy: 0.6667\n",
            "Epoch 15/30\n",
            "9/9 [==============================] - 12s 1s/step - batch: 4.0000 - size: 16.0000 - loss: 0.1206 - accuracy: 0.9641 - val_loss: 1.0887 - val_accuracy: 0.7130\n",
            "Epoch 16/30\n",
            "9/9 [==============================] - 7s 641ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0630 - accuracy: 0.9850 - val_loss: 1.2725 - val_accuracy: 0.6667\n",
            "Epoch 17/30\n",
            "9/9 [==============================] - 8s 988ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0672 - accuracy: 0.9780 - val_loss: 1.2596 - val_accuracy: 0.6481\n",
            "Epoch 18/30\n",
            "9/9 [==============================] - 6s 612ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0702 - accuracy: 0.9803 - val_loss: 1.3612 - val_accuracy: 0.6528\n",
            "Epoch 19/30\n",
            "9/9 [==============================] - 6s 708ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1004 - accuracy: 0.9688 - val_loss: 1.2879 - val_accuracy: 0.6898\n",
            "Epoch 20/30\n",
            "9/9 [==============================] - 6s 622ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.1086 - accuracy: 0.9676 - val_loss: 0.9000 - val_accuracy: 0.6852\n",
            "Epoch 21/30\n",
            "9/9 [==============================] - 5s 597ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0896 - accuracy: 0.9664 - val_loss: 0.8940 - val_accuracy: 0.7176\n",
            "Epoch 22/30\n",
            "9/9 [==============================] - 10s 1s/step - batch: 4.0000 - size: 16.0000 - loss: 0.0617 - accuracy: 0.9757 - val_loss: 1.0890 - val_accuracy: 0.6991\n",
            "Epoch 23/30\n",
            "9/9 [==============================] - 7s 757ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0597 - accuracy: 0.9803 - val_loss: 1.1886 - val_accuracy: 0.6528\n",
            "Epoch 24/30\n",
            "9/9 [==============================] - 7s 696ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0868 - accuracy: 0.9769 - val_loss: 1.2143 - val_accuracy: 0.6898\n",
            "Epoch 25/30\n",
            "9/9 [==============================] - 6s 737ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0483 - accuracy: 0.9861 - val_loss: 1.3158 - val_accuracy: 0.6574\n",
            "Epoch 26/30\n",
            "9/9 [==============================] - 6s 596ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0527 - accuracy: 0.9780 - val_loss: 1.3487 - val_accuracy: 0.6713\n",
            "Epoch 27/30\n",
            "9/9 [==============================] - 5s 605ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0621 - accuracy: 0.9803 - val_loss: 1.6457 - val_accuracy: 0.6019\n",
            "Epoch 28/30\n",
            "9/9 [==============================] - 8s 899ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0616 - accuracy: 0.9803 - val_loss: 1.4575 - val_accuracy: 0.5787\n",
            "Epoch 29/30\n",
            "9/9 [==============================] - 8s 932ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0735 - accuracy: 0.9769 - val_loss: 0.9362 - val_accuracy: 0.6435\n",
            "Epoch 30/30\n",
            "9/9 [==============================] - 5s 606ms/step - batch: 4.0000 - size: 16.0000 - loss: 0.0472 - accuracy: 0.9838 - val_loss: 1.0326 - val_accuracy: 0.6852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] serializing network...\")\n",
        "\n",
        "model.save(\"multi_class.hdf5\")\n",
        "\n",
        "# save the multi-label binarizer to disk\n",
        "print(\"[INFO] serializing label binarizer...\")\n",
        "\n",
        "with open(\"model_labels\", \"wb\") as f:\n",
        "  f.write(pickle.dumps(mlb))\n",
        "  f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_pERlnYu1TJ",
        "outputId": "d1d6ac91-09c2-40e7-9015-67c23d0de24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] serializing network...\n",
            "[INFO] serializing label binarizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.savefig(\"plot\")"
      ],
      "metadata": {
        "id": "ZcHMoMbOBZAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Keras multi-label classification to new images"
      ],
      "metadata": {
        "id": "MxvPTnqyE2w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "image = cv2.imread(\"/content/example_03.jpg\")\n",
        "\n",
        "# pre-process the image for classification\n",
        "image = cv2.resize(image, (96, 96))\n",
        "image = image.astype(\"float\") / 255.0\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "\n",
        "# load labels\n",
        "with open(\"/content/model_labels\", 'rb') as f:\n",
        "  mlb = pickle.load(f)\n",
        "\n",
        "# load model achitecture and weights\n",
        "model = load_model(\"/content/multi_class.hdf5\")\n",
        "\n",
        "predict = model.predict(image)[0]\n",
        "idxs = np.argsort(predict)[::-1][:2]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kh_mU2EEkwq",
        "outputId": "7a9d4c36-823a-410d-e797-2eb3abccac9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ]
    }
  ]
}